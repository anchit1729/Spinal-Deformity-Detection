{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab5ec99",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "Here, we train the UNet model on our dataset.\n",
    "First, the `Trainer` class is defined. This class keeps track of all relevant parameters while training, and combines the forward and backward propagation through the network in a loop that is passed with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset = None,\n",
    "                 lr_scheduler: torch.optim.lr_scheduler = None,\n",
    "                 epochs: int = 100,\n",
    "                 epoch: int = 0,\n",
    "                 notebook: bool = False\n",
    "                 ):\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.epoch = epoch\n",
    "        self.notebook = notebook\n",
    "\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.learning_rate = []\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        progressbar = trange(self.epochs, desc='Progress')\n",
    "        for i in progressbar:\n",
    "            \"\"\"Epoch counter\"\"\"\n",
    "            self.epoch += 1  # epoch counter\n",
    "\n",
    "            \"\"\"Training block\"\"\"\n",
    "            self._train()\n",
    "\n",
    "            \"\"\"Validation block\"\"\"\n",
    "            if self.validation_DataLoader is not None:\n",
    "                self._validate()\n",
    "\n",
    "            \"\"\"Learning rate scheduler block\"\"\"\n",
    "            if self.lr_scheduler is not None:\n",
    "                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':\n",
    "                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss\n",
    "                else:\n",
    "                    self.lr_scheduler.step()  # learning rate scheduler step\n",
    "        return self.training_loss, self.validation_loss, self.learning_rate\n",
    "\n",
    "    def _train(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        self.model.train()  # train mode\n",
    "        train_losses = []  # accumulate the losses here\n",
    "        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),\n",
    "                          leave=False)\n",
    "\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input = x.to(self.device) # send to device (GPU or CPU)\n",
    "            target = y.to(self.device) # send to device (GPU or CPU)\n",
    "            self.optimizer.zero_grad()  # zerograd the parameters\n",
    "            out = self.model(input).to(self.device)  # one forward pass\n",
    "            loss = self.criterion(out, target)  # calculate loss\n",
    "            loss_value = loss.item()\n",
    "            train_losses.append(loss_value)\n",
    "            loss.backward()  # one backward pass\n",
    "            self.optimizer.step()  # update the parameters\n",
    "\n",
    "            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar\n",
    "\n",
    "        self.training_loss.append(np.mean(train_losses))\n",
    "        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        batch_iter.close()\n",
    "\n",
    "    def _validate(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        self.model.eval()  # evaluation mode\n",
    "        valid_losses = []  # accumulate the losses here\n",
    "        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),\n",
    "                          leave=False)\n",
    "        predictions = []\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = self.model(input).to(self.device)\n",
    "                #out = out.squeeze()    # remove extra dimension\n",
    "                loss = self.criterion(out, target)\n",
    "                loss_value = loss.item()\n",
    "                valid_losses.append(loss_value)\n",
    "\n",
    "                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')\n",
    "\n",
    "        self.validation_loss.append(np.mean(valid_losses))\n",
    "\n",
    "        batch_iter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0d9d1",
   "metadata": {},
   "source": [
    "Now, we run the data generators once more, loading in our dataset and performing augmentations such as random flips (p = 0.5) and random rotations (up to 45 degrees). Since UNet typically requires ~500 images to train and we have access to over 1000, a train-validation split of 80:20 works just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import imagecodecs\n",
    "import pathlib\n",
    "import torch\n",
    "import import_ipynb\n",
    "\n",
    "import albumentations\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "from customdatasets import SegmentationDataSet\n",
    "from transformations import ComposeDouble, AlbuSeg2d, FunctionWrapperDouble, normalize_01, create_dense_target\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'cleaned_data'\n",
    "\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'data_clean')\n",
    "inputs.sort()\n",
    "targets = get_filenames_of_path(root / 'labels_clean')\n",
    "targets.sort()\n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble([\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=True,\n",
    "                          target=False,\n",
    "                          output_shape=(896, 640, 3)),\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=False,\n",
    "                          target=True,\n",
    "                          output_shape=(896, 640),\n",
    "                          order=0,\n",
    "                          anti_aliasing=True,\n",
    "                          preserve_range=True),\n",
    "    AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n",
    "    AlbuSeg2d(albumentations.Rotate(limit=45)),\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01, input=True, target=True)\n",
    "])\n",
    "# 896, 640, 3\n",
    "# 896, 640\n",
    "# validation transformations\n",
    "transforms_validation = ComposeDouble([\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=True,\n",
    "                          target=False,\n",
    "                          output_shape=(896, 640, 3)),\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=False,\n",
    "                          target=True,\n",
    "                          output_shape=(896, 640),\n",
    "                          order=0,\n",
    "                          anti_aliasing=True,\n",
    "                          preserve_range=True),\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01, input=True, target=True)\n",
    "])\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms_training)\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms_validation)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=2,\n",
    "                                 shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=2,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f4e4f",
   "metadata": {},
   "source": [
    "Next, the `Trainer` object can be instantiated, and training can be started. We use a UNet model with resnet34 as the encoder backend (larger resnets tend to converge much more slowly with diminishing returns in terms of quality). The weights of the encoder are those obtained from training on the imagenet dataset, which gives the network somewhat of a head-start. SCSE (squeeze + excite) is a technique introduced recently that improves the model's robustness in terms of the input image quality (this showed noticeable improvements in pedicle isolation and reduced fuzziness in outputs). The decoder is a typical CNN with a symmetric number of upsampling steps (here, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bca01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "# try out the segmentation models library\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "# model\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    decoder_attention_type=\"scse\",  # use scse (squeeze + excite) to improve model robustness\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ").to(device)\n",
    "\n",
    "# criterion - the value that is optimized \n",
    "criterion = smp.losses.JaccardLoss(\n",
    "    mode=\"multiclass\", \n",
    "    smooth=1e-3,\n",
    ")\n",
    "\n",
    "# optimizer - SGD often generalizes better than Adam, even though Adam can be faster in many cases\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5),\n",
    "                  epochs=100,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ce551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from visualizetraining import plot_training\n",
    "fig = plot_training(training_losses, validation_losses, lr_rates, gaussian=True, sigma=1, figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251bb04-c2b9-44aa-af2d-ca1d073ef3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'unet_model_v11.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a8c64-5ec0-4a22-a912-b6fa9313007c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
